{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# pd.reset_option('display.max_rows')\n",
    "# pd.reset_option('display.max_columns')\n",
    "# pd.reset_option('display.width')\n",
    "# pd.reset_option('display.max_colwidth')\n",
    "\n",
    "# pd.reset_option('all')\n",
    "\n",
    "anomaly_data = pd.read_csv(\"rawtable-anomaly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired_columns = ['Y', 'Data', 'XAU BGNL', 'BDIY', 'CRY', 'DXY', 'JPY', 'GBP','Cl1', 'VIX', 'USGG30YR', 'GT10', 'USGG2YR', 'USGG3M', 'US0001M', 'EONIA','LUMSTRUU']\n",
    "desired_columns = ['Y', 'Data', 'XAU BGNL', 'BDIY', 'CRY', 'DXY', 'VIX', 'Cl1']\n",
    "anomaly_data = pd.read_csv(\"anomaly_detection_financial_data.csv\")\n",
    "anomaly_data = anomaly_data[desired_columns]\n",
    "anomaly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_anomaly_data = anomaly_data[desired_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_duplicates = new_anomaly_data.duplicated().sum()\n",
    "total_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks for missing values in the entire DataFrame\n",
    "# total_missing = new_anomaly_data.isna().sum().sum()\n",
    "\n",
    "# Checks for missing values in each column\n",
    "total_missing = new_anomaly_data.isnull().sum()\n",
    "total_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_anomaly_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_anomaly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      "0    874\n",
      "1    237\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_anomaly_data['Y'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "new_anomaly_data['Y'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Target Y anomaly data')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "def plot_anomalies_over_time(data, y_true, y_pred):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # Convert dates to datetime if they're not already\n",
    "    dates = pd.to_datetime(data['Data'])\n",
    "    \n",
    "    # Create boolean masks with matching indices\n",
    "    true_mask = pd.Series(y_true == 1, index=data.index)\n",
    "    pred_mask = pd.Series(y_pred == 1, index=data.index)\n",
    "    \n",
    "    # Plot actual anomalies\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(dates, data['VIX'], 'b-', label='VIX', alpha=0.5)\n",
    "    plt.scatter(dates[true_mask], data['VIX'][true_mask], \n",
    "                color='red', label='Actual Anomalies', marker='o')\n",
    "    plt.title('Actual Anomalies')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot predicted anomalies\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(dates, data['VIX'], 'b-', label='VIX', alpha=0.5)\n",
    "    plt.scatter(dates[pred_mask], data['VIX'][pred_mask], \n",
    "                color='orange', label='Predicted Anomalies', marker='x')\n",
    "    plt.title('Predicted Anomalies')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_proba):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    # If using pipeline, get the classifier\n",
    "    if hasattr(model, 'named_steps'):\n",
    "        classifier = model.named_steps['classifier']\n",
    "    else:\n",
    "        classifier = model\n",
    "        \n",
    "    # Create DataFrame with feature importances\n",
    "    importances = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': classifier.feature_importances_\n",
    "    }).sort_values('importance', ascending=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.barh(range(len(importances)), importances['importance'])\n",
    "    plt.yticks(range(len(importances)), importances['feature'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_enhanced_anomalies_over_time(data, y_true, y_pred, fold):\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    dates = pd.to_datetime(data['Data'])\n",
    "    \n",
    "    # Create masks\n",
    "    true_mask = pd.Series(y_true == 1, index=data.index)\n",
    "    pred_mask = pd.Series(y_pred == 1, index=data.index)\n",
    "    \n",
    "    # True Positives, False Positives, False Negatives\n",
    "    tp_mask = true_mask & pred_mask\n",
    "    fp_mask = (~true_mask) & pred_mask\n",
    "    fn_mask = true_mask & (~pred_mask)\n",
    "    \n",
    "    plt.plot(dates, data['VIX'], 'b-', label='VIX', alpha=0.5)\n",
    "    plt.scatter(dates[tp_mask], data['VIX'][tp_mask], \n",
    "                color='green', label='True Positives', marker='o')\n",
    "    plt.scatter(dates[fp_mask], data['VIX'][fp_mask], \n",
    "                color='red', label='False Positives', marker='x')\n",
    "    plt.scatter(dates[fn_mask], data['VIX'][fn_mask], \n",
    "                color='orange', label='False Negatives', marker='s')\n",
    "    \n",
    "    plt.title(f'Anomaly Detection Results - Fold {fold}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_pickle(model, filename=None, fold=None, X=None, y=None):\n",
    "    if filename is None:\n",
    "        filename = f'anomaly_model_randomforest_{fold}.pkl'\n",
    "    \n",
    "    # Calculate model performance metrics\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    \n",
    "    # Create metadata dictionary\n",
    "    model_info = {\n",
    "        'model': model,\n",
    "        'metadata': {\n",
    "            'fold': fold,\n",
    "            'features': X.columns.tolist(),\n",
    "            'n_samples': len(X),\n",
    "            'performance': {\n",
    "                'accuracy': accuracy,\n",
    "                'f1_score': f1\n",
    "            },\n",
    "            'model_params': model.get_params(),\n",
    "            'class_distribution': pd.Series(y).value_counts().to_dict()\n",
    "        }\n",
    "    }\n",
    "    # Save model with metadata\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model_info, file)\n",
    "    print(f\"Model saved as: {filename}\")\n",
    "    print(f\"Metrics - Accuracy: {accuracy:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "def load_model(filename):\n",
    "    if filename.endswith('.pkl'):\n",
    "        with open(filename, 'rb') as file:\n",
    "            model_info = pickle.load(file)\n",
    "            \n",
    "        # Print metadata\n",
    "        print(\"\\nModel Metadata:\")\n",
    "        for key, value in model_info['metadata'].items():\n",
    "            print(f\"{key}: {value}\")\n",
    "            \n",
    "        return model_info['model']\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    \n",
    "def add_time_features(df):\n",
    "    # Convert to datetime\n",
    "    df = df.copy()\n",
    "    df['Data'] = pd.to_datetime(df['Data'])\n",
    "    \n",
    "    # Extract time components\n",
    "    df['Month'] = df['Data'].dt.month\n",
    "    df['Quarter'] = df['Data'].dt.quarter\n",
    "    df['Year'] = df['Data'].dt.year\n",
    "    df['DayOfWeek'] = df['Data'].dt.dayofweek\n",
    "    \n",
    "    # Create cyclical features for Month and DayOfWeek\n",
    "    df['Month_sin'] = np.sin(2 * np.pi * df['Month']/12)\n",
    "    df['Month_cos'] = np.cos(2 * np.pi * df['Month']/12)\n",
    "    df['DayOfWeek_sin'] = np.sin(2 * np.pi * df['DayOfWeek']/7)\n",
    "    df['DayOfWeek_cos'] = np.cos(2 * np.pi * df['DayOfWeek']/7)\n",
    "    \n",
    "    return df\n",
    "\n",
    "data_with_features = add_time_features(new_anomaly_data)    \n",
    "    \n",
    "X = new_anomaly_data.drop(['Y', 'Data'], axis=1)\n",
    "y = new_anomaly_data['Y']\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "all_predictions = []\n",
    "all_true_values = []\n",
    "\n",
    "\n",
    "# model = RandomForestClassifier(\n",
    "#     # Handle Overfitting\n",
    "#     max_depth=5,\n",
    "#     min_samples_split=10,\n",
    "#     min_samples_leaf=8,\n",
    "#     max_features='log2',\n",
    "#     n_estimators=200,\n",
    "    \n",
    "#     # Better class imbalance handling\n",
    "#     class_weight={\n",
    "#         0: 1,\n",
    "#         1: 3\n",
    "#     },\n",
    "    \n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "model = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        max_depth=5,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        n_estimators=300,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "def predict_with_threshold(model, X, threshold=0.5):\n",
    "    \"\"\"Make predictions using a lower threshold for the minority class\"\"\"\n",
    "    y_proba = model.predict_proba(X)\n",
    "    return (y_proba[:, 1] >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    print(f\"\\nFold {fold} class distribution:\")\n",
    "    print(\"Train:\", pd.Series(y_train).value_counts())\n",
    "    print(\"Test:\", pd.Series(y_test).value_counts())\n",
    "    \n",
    "    # Train model\n",
    "    # model.fit(X_train, y_train)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    # y_pred = model.predict(X_test)\n",
    "    y_pred = predict_with_threshold(model, X_test, threshold=0.2)\n",
    "    \n",
    "    # Calculate scores\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    # Store scores\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_values.extend(y_test)\n",
    "    \n",
    "    # model = RandomForestClassifier(random_state=42)\n",
    "    # model.fit(X_train, y_train)\n",
    "    \n",
    "    # save_model_pickle(model, filename=f'anomaly_model_randomforest_{fold}.pkl')\n",
    "    save_model_pickle(\n",
    "        model=model,\n",
    "        filename=f'anomaly_model_randomforest_{fold}.pkl',\n",
    "        fold=fold,\n",
    "        X=X_train,\n",
    "        y=y_train\n",
    "    )\n",
    "    # save_model_pickle(\n",
    "    #     model=model,\n",
    "    #     filename=f'anomaly_model_randomforest_{fold}.pkl',\n",
    "    #     fold=fold,\n",
    "    #     X=X_train,\n",
    "    #     y=y_train\n",
    "    # )\n",
    "    \n",
    "    \n",
    "    print(f\"\\nFold {fold+1} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"F1-Score: {f1:.3f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    print(f\"\\nFold {fold} Visualizations:\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    plot_confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Time Series Plot\n",
    "    # test_data = data_with_features.iloc[test_idx].copy()\n",
    "    # plot_anomalies_over_time(test_data, y_test, y_pred)\n",
    "    test_data = data_with_features.iloc[test_idx].copy()\n",
    "    plot_enhanced_anomalies_over_time(test_data, y_test, y_pred, fold)\n",
    "    \n",
    "    # ROC Curve\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    plot_roc_curve(y_test, y_pred_proba)\n",
    "    \n",
    "    # Feature Importance\n",
    "    plot_feature_importance(model, X.columns)\n",
    "\n",
    "\n",
    "print(\"\\nOverall Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_scores):.3f} (+/- {np.std(accuracy_scores):.3f})\")\n",
    "print(f\"Average F1-Score: {np.mean(f1_scores):.3f} (+/- {np.std(f1_scores):.3f})\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(len(accuracy_scores)), accuracy_scores, 'b-', label='Accuracy')\n",
    "plt.plot(range(len(f1_scores)), f1_scores, 'r-', label='F1-Score')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cumulative Performance Plot\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.cumsum(accuracy_scores)/range(1, len(accuracy_scores)+1), \n",
    "         'b-', label='Running Average Accuracy')\n",
    "plt.plot(np.cumsum(f1_scores)/range(1, len(f1_scores)+1), \n",
    "         'r-', label='Running Average F1')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Cumulative Average Score')\n",
    "plt.title('Cumulative Model Performance')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 2. Class Distribution Plot\n",
    "plt.subplot(2, 1, 2)\n",
    "fold_numbers = range(len(accuracy_scores))\n",
    "class_ratios = []\n",
    "for fold, (_, test_idx) in enumerate(tscv.split(X)):\n",
    "    y_test_fold = y.iloc[test_idx]\n",
    "    ratio = (y_test_fold == 1).sum() / len(y_test_fold)\n",
    "    class_ratios.append(ratio)\n",
    "\n",
    "plt.bar(fold_numbers, class_ratios, alpha=0.5, label='Anomaly Ratio')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Ratio of Anomalies')\n",
    "plt.title('Class Distribution Across Folds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section: XGBoost functions\n",
    "\n",
    "\n",
    "def calculate_rsi(series, window=14):\n",
    "    \"\"\"Calculate RSI technical indicator\"\"\"\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def create_time_features(df):\n",
    "    \"\"\"Create time-based and technical features\"\"\"\n",
    "    df = df.copy()\n",
    "    df['Data'] = pd.to_datetime(df['Data'])\n",
    "    \n",
    "    # Basic time features\n",
    "    df['Month'] = df['Data'].dt.month\n",
    "    df['DayOfWeek'] = df['Data'].dt.dayofweek\n",
    "    df['Quarter'] = df['Data'].dt.quarter\n",
    "    \n",
    "    # RSI features for different windows\n",
    "    for window in [5, 14, 21]:\n",
    "        # Calculate RSI for VIX\n",
    "        df[f'VIX_RSI_{window}'] = calculate_rsi(df['VIX'], window)\n",
    "        \n",
    "        # Calculate RSI for other relevant numeric columns\n",
    "        for col in ['DXY', 'XAU BGNL', 'Cl1']:\n",
    "            df[f'{col}_RSI_{window}'] = calculate_rsi(df[col], window)\n",
    "    \n",
    "    # Additional technical features\n",
    "    for window in [5, 10, 20]:\n",
    "        # Rolling statistics for VIX\n",
    "        df[f'VIX_MA_{window}'] = df['VIX'].rolling(window=window).mean()\n",
    "        df[f'VIX_STD_{window}'] = df['VIX'].rolling(window=window).std()\n",
    "        \n",
    "        # Price changes\n",
    "        df[f'VIX_Change_{window}'] = df['VIX'].pct_change(window)\n",
    "        df[f'DXY_Change_{window}'] = df['DXY'].pct_change(window)\n",
    "    \n",
    "    # Cross-asset ratios\n",
    "    df['VIX_DXY_Ratio'] = df['VIX'] / df['DXY']\n",
    "    df['Gold_Oil_Ratio'] = df['XAU BGNL'] / df['Cl1']\n",
    "    \n",
    "    # RSI crossovers and extremes\n",
    "    df['VIX_RSI_Cross'] = (df['VIX_RSI_5'] > df['VIX_RSI_14']).astype(int)\n",
    "    df['VIX_RSI_Overbought'] = (df['VIX_RSI_14'] > 70).astype(int)\n",
    "    df['VIX_RSI_Oversold'] = (df['VIX_RSI_14'] < 30).astype(int)\n",
    "    \n",
    "    # Fill NaN values\n",
    "    df = df.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def find_optimal_threshold(y_true, y_pred_proba):\n",
    "    \"\"\"Find the optimal probability threshold for classification\"\"\"\n",
    "    thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    \n",
    "    return best_threshold\n",
    "\n",
    "# Create time-based features\n",
    "def create_time_features2(df):\n",
    "    df = df.copy()\n",
    "    df['Data'] = pd.to_datetime(df['Data'])\n",
    "    \n",
    "    # Basic time features\n",
    "    df['Month'] = df['Data'].dt.month\n",
    "    df['DayOfWeek'] = df['Data'].dt.dayofweek\n",
    "    \n",
    "    # Lag features\n",
    "    df['VIX_Lag1'] = df['VIX'].shift(1)\n",
    "    df['VIX_Lag5'] = df['VIX'].shift(5)\n",
    "    \n",
    "    # Rolling features\n",
    "    df['VIX_MA5'] = df['VIX'].rolling(window=5).mean()\n",
    "    df['VIX_STD5'] = df['VIX'].rolling(window=5).std()\n",
    "    \n",
    "    return df.fillna(method='bfill')\n",
    "\n",
    "def plot_xgb_importance(model, X):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=importance_df.head(15), x='importance', y='feature')\n",
    "    plt.title('Top 15 Most Important Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def select_features(X_train, y_train, X_test):\n",
    "    \"\"\"Select most important features\"\"\"\n",
    "    selector = SelectFromModel(\n",
    "        xgb.XGBClassifier(random_state=42),\n",
    "        threshold='median'  # Select top 50% of features\n",
    "    )\n",
    "    \n",
    "    # Fit and transform\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_features = X_train.columns[selector.get_support()].tolist()\n",
    "    return X_train_selected, X_test_selected, selected_features\n",
    "\n",
    "def save_model_pickleXGB(model, filename, fold, X, y):\n",
    "    \"\"\"Save model and its metadata\"\"\"\n",
    "    # Store model and feature names together\n",
    "    model_data = {\n",
    "        'model': model,\n",
    "        'feature_names': list(X.columns),  # Save feature names\n",
    "        'fold': fold,\n",
    "        'training_shape': X.shape,\n",
    "        'metrics': {\n",
    "            'accuracy': accuracy_score(y, model.predict(X)),\n",
    "            'f1': f1_score(y, model.predict(X))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model_data, f)\n",
    "        \n",
    "def load_model_pickleXGB(filename):\n",
    "    \"\"\"Load model and verify features\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    return model_data['model'], model_data['feature_names']\n",
    "\n",
    "# When using the model:\n",
    "def predict_with_modelXGB(model, X, feature_names):\n",
    "    # Ensure X has the same features in the same order\n",
    "    X = X[feature_names]\n",
    "    return model.predict(X)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section: XGBoost\n",
    "\n",
    "# Prepare data with time features\n",
    "# data_with_features = create_time_features(new_anomaly_data)\n",
    "# data_with_features = create_time_features2(new_anomaly_data)\n",
    "data_with_features = create_time_features(new_anomaly_data)\n",
    "X = data_with_features.drop(['Y', 'Data'], axis=1)\n",
    "y = data_with_features['Y']\n",
    "\n",
    "# Initialize metrics storage\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Time series cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Feature selection\n",
    "    # X_train_selected, X_test_selected, selected_features = select_features(X_train, y_train, X_test)\n",
    "    # print(f\"Selected {len(selected_features)} features\")\n",
    "    \n",
    "    # Train a preliminary model to get feature importance\n",
    "    prelim_model = xgb.XGBClassifier(random_state=42)\n",
    "    prelim_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Select important features\n",
    "    importance_threshold = np.median(prelim_model.feature_importances_)\n",
    "    important_features = X_train.columns[prelim_model.feature_importances_ > importance_threshold].tolist()\n",
    "    \n",
    "    # Filter features\n",
    "    X_train_selected = X_train[important_features]\n",
    "    X_test_selected = X_test[important_features]\n",
    "    \n",
    "    print(f\"Selected {len(important_features)} features\")\n",
    "    \n",
    "    # Calculate minority class ratio\n",
    "    minority_ratio = len(y_train[y_train==1]) / len(y_train[y_train==0])\n",
    "    target_ratio = min(0.5, minority_ratio * 2)  # Double the minority ratio, but cap at 0.5\n",
    "    \n",
    "    try:\n",
    "        # Apply SMOTE: with adaptive sampling strategy\n",
    "        smote = SMOTE(\n",
    "            random_state=42,\n",
    "            # sampling_strategy=target_ratio,\n",
    "            sampling_strategy=0.5,\n",
    "            k_neighbors=min(5, len(y_train[y_train==1])-1)  # Adjust neighbors based on minority class size\n",
    "        )\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_selected, y_train)\n",
    "        print(f\"Applied SMOTE - Original balance: {minority_ratio:.3f}, New balance: {target_ratio:.3f}\")\n",
    "    except ValueError:\n",
    "        # If SMOTE fails, use original data\n",
    "        print(\"SMOTE failed - using original imbalanced data\")\n",
    "        X_train_balanced, y_train_balanced = X_train_selected, y_train\n",
    "    \n",
    "    # Apply SMOTE only on training data\n",
    "    # smote = SMOTE(random_state=42, sampling_strategy=0.3)  # Create minority class to be 30% of majority\n",
    "    # X_train_balanced, y_train_balanced = smote.fit_resample(X_train_selected, y_train)\n",
    "    \n",
    "    # Calculate class weight\n",
    "    # scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
    "    # scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1]) * 2\n",
    "    class_counts = y_train.value_counts()\n",
    "    scale_pos_weight = class_counts[0] / class_counts[1]\n",
    "    # 3. Decrease weight with multiplier 0.75 (reduce false positives 25% decrease)\n",
    "    scale_pos_weight = (class_counts[0] / class_counts[1]) * 0.05\n",
    "    \n",
    "    # model params:\n",
    "    model = xgb.XGBClassifier(\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=500,\n",
    "        max_depth=4,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.5,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        early_stopping_rounds=20,\n",
    "        # Add class weights instead of SMOTE if it fails\n",
    "        # scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]),\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    # model.fit(\n",
    "    #     X_train, y_train,\n",
    "    #     eval_set=[(X_test, y_test)],\n",
    "    #     # eval_metric=['auc', 'logloss'],\n",
    "    #     # early_stopping_rounds=10,\n",
    "    #     verbose=False\n",
    "    # )\n",
    "    model.fit(\n",
    "        X_train_balanced, \n",
    "        y_train_balanced,\n",
    "        eval_set=[(X_test_selected, y_test)],\n",
    "        # early_stopping_rounds=20,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    # y_pred = model.predict(X_test)\n",
    "    # y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    # optimal_threshold = find_optimal_threshold(y_test, y_pred_proba)\n",
    "    # y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    \n",
    "    y_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "    optimal_threshold = find_optimal_threshold(y_test, y_pred_proba)\n",
    "    y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    auc_scores.append(auc)\n",
    "    \n",
    "    # save_model_pickle(\n",
    "    #     model=model,\n",
    "    #     filename=f'anomaly_model_xgboost_{fold}.pkl',\n",
    "    #     fold=fold,\n",
    "    #     X=X_train,\n",
    "    #     y=y_train\n",
    "    # )\n",
    "    save_model_pickleXGB(\n",
    "        model=model,\n",
    "        filename=f'anomaly_model_xgboost_{fold}.pkl',\n",
    "        fold=fold,\n",
    "        X=X_train_selected,\n",
    "        y=y_train\n",
    "    )\n",
    "    \n",
    "     # Store feature importance\n",
    "    fold_importance = pd.DataFrame({\n",
    "        'feature': important_features,\n",
    "        'importance': model.feature_importances_,\n",
    "        'fold': fold + 1\n",
    "    })\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance])\n",
    "    \n",
    "    print(f\"Optimal Threshold: {optimal_threshold:.3f}\")\n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"F1-Score: {f1:.3f}\")\n",
    "    print(f\"AUC-ROC: {auc:.3f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Plot feature importance\n",
    "    # plot_xgb_importance(model, X)\n",
    "    # Print selected features for first fold\n",
    "    if fold == 0:\n",
    "        print(\"\\nSelected Features:\")\n",
    "        for feature in important_features:\n",
    "            print(f\"- {feature}\")\n",
    "\n",
    "# Print overall results\n",
    "print(\"\\nOverall Results:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_scores):.3f} (±{np.std(accuracy_scores):.3f})\")\n",
    "print(f\"Average F1-Score: {np.mean(f1_scores):.3f} (±{np.std(f1_scores):.3f})\")\n",
    "print(f\"Average AUC-ROC: {np.mean(auc_scores):.3f} (±{np.std(auc_scores):.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic Performance Metrics\n",
    "def evaluate_model_performance(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"Calculate and display comprehensive model performance metrics\"\"\"\n",
    "    print(\"Model Performance Metrics:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall: {recall:.3f}\")\n",
    "    print(f\"F1-Score: {f1:.3f}\")\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        auc_roc = roc_auc_score(y_true, y_pred_proba)\n",
    "        print(f\"AUC-ROC: {auc_roc:.3f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        # ROC Curve\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_roc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Precision-Recall Curve\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)\n",
    "        plt.plot(recall, precision)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.show()\n",
    "\n",
    "# 2. Use the function\n",
    "# Get predictions\n",
    "model, feature_names = load_model_pickleXGB(f'anomaly_model_xgboost_{4}.pkl')\n",
    "X = data_with_features[feature_names]\n",
    "y_pred = model.predict(X)\n",
    "y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "evaluate_model_performance(y, y_pred, y_pred_proba)\n",
    "\n",
    "# 3. Additional Analysis: Prediction Distribution\n",
    "def analyze_predictions(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"Analyze prediction patterns and distributions\"\"\"\n",
    "    print(\"\\nPrediction Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Class distribution\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    print(pd.Series(y_pred).value_counts(normalize=True))\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        # Probability distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(y_pred_proba, bins=50)\n",
    "        plt.title('Distribution of Prediction Probabilities')\n",
    "        plt.xlabel('Probability')\n",
    "        plt.show()\n",
    "        \n",
    "        # Probability distribution by true class\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=pd.DataFrame({\n",
    "            'Probability': y_pred_proba,\n",
    "            'True Class': y_true\n",
    "        }), x='Probability', hue='True Class', bins=50)\n",
    "        plt.title('Distribution of Prediction Probabilities by True Class')\n",
    "        plt.show()\n",
    "\n",
    "# Use the additional analysis\n",
    "analyze_predictions(y, y_pred, y_pred_proba)\n",
    "\n",
    "# 4. Time-based Performance (if you have dates)\n",
    "def analyze_temporal_performance(dates, y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"Analyze model performance over time\"\"\"\n",
    "    results_df = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'True': y_true,\n",
    "        'Predicted': y_pred,\n",
    "        'Probability': y_pred_proba if y_pred_proba is not None else y_pred\n",
    "    })\n",
    "    \n",
    "    # Monthly performance\n",
    "    results_df['Month'] = pd.to_datetime(results_df['Date']).dt.to_period('M')\n",
    "    monthly_performance = results_df.groupby('Month').apply(\n",
    "        lambda x: accuracy_score(x['True'], x['Predicted'])\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    monthly_performance.plot(kind='line', marker='o')\n",
    "    plt.title('Model Accuracy Over Time')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Use temporal analysis if you have dates\n",
    "if 'Data' in data_with_features.columns:\n",
    "    analyze_temporal_performance(\n",
    "        data_with_features['Data'],\n",
    "        y,\n",
    "        y_pred,\n",
    "        y_pred_proba\n",
    "    )\n",
    "# data_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "\n",
    "# 1. Load and prepare data\n",
    "def prepare_prediction_data(file_path):\n",
    "    \"\"\"Prepare data for prediction with error checking\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Verify required columns\n",
    "        missing_cols = set(desired_columns) - set(data.columns)\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "            \n",
    "        # Select columns and create features\n",
    "        data = data[desired_columns]\n",
    "        data_with_features = create_time_features(data)\n",
    "        \n",
    "        # Prepare X and y\n",
    "        X = data_with_features.drop(['Y', 'Data'], axis=1)\n",
    "        y = data_with_features['Y']\n",
    "        \n",
    "        return X, y, data_with_features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing data from {file_path}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# 2. Load model and make predictions\n",
    "def make_predictions(X, model, feature_names):\n",
    "    \"\"\"Make predictions with feature verification\"\"\"\n",
    "    try:\n",
    "        # Verify features\n",
    "        missing_features = set(feature_names) - set(X.columns)\n",
    "        if missing_features:\n",
    "            print(f\"Warning: Missing features: {missing_features}\")\n",
    "            \n",
    "        # Select correct features in correct order\n",
    "        X_pred = X[feature_names]\n",
    "        \n",
    "        # Make predictions\n",
    "        return model.predict(X_pred), model.predict_proba(X_pred)[:, 1]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error making predictions: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# 3. Use the functions\n",
    "# Load first dataset\n",
    "X1, y1, data1 = prepare_prediction_data(\"rawtable-anomaly.csv\")\n",
    "X2, y2, data2 = prepare_prediction_data(\"anomaly_detection_financial_data_half_2021_2024.csv\")\n",
    "X3, y3, data3 = prepare_prediction_data(\"anomaly_detection_financial_data.csv\")\n",
    "\n",
    "# Load model\n",
    "model, feature_names = load_model_pickleXGB(f'anomaly_model_xgboost_{4}.pkl')\n",
    "\n",
    "# Debug info\n",
    "print(\"Required features:\", len(feature_names))\n",
    "print(\"Available features:\", len(data1.columns) if data1 is not None else 0)\n",
    "\n",
    "# Make predictions\n",
    "if X2 is not None:\n",
    "    # Get both predictions and probabilities at once\n",
    "    y_pred, y_pred_proba = make_predictions(X2, model, feature_names)\n",
    "    \n",
    "    if y_pred is not None:\n",
    "        print(\"\\nFeature names in model:\", feature_names)\n",
    "        # print(\"Features in data:\", X3.columns.tolist())\n",
    "        \n",
    "        # Evaluate performance\n",
    "        evaluate_model_performance(y2, y_pred, y_pred_proba)\n",
    "        print(\"\\nPrediction shape:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# section: LSTM\n",
    "\n",
    "def bivariate_analysis(df, target_col='Y'):\n",
    "    \"\"\"\n",
    "    Perform bivariate analysis between target variable and all other numeric columns\n",
    "    \"\"\"\n",
    "    # Get numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_cols.remove(target_col)  # Remove target from features\n",
    "    \n",
    "    # Initialize statistical results dictionary\n",
    "    stats_results = {}\n",
    "    \n",
    "    # Create subplots for each feature\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, col in enumerate(numeric_cols):\n",
    "        # 1. Box Plot\n",
    "        plt.subplot(n_rows, n_cols, idx+1)\n",
    "        sns.boxplot(x=df[target_col], y=df[col])\n",
    "        plt.title(f'Box Plot: {col} by {target_col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # 2. Statistical Tests\n",
    "        # Mann-Whitney U test for non-normal distributions\n",
    "        stat, p_value = stats.mannwhitneyu(\n",
    "            df[df[target_col]==0][col].dropna(),\n",
    "            df[df[target_col]==1][col].dropna(),\n",
    "            alternative='two-sided'\n",
    "        )\n",
    "        \n",
    "        # Calculate Effect Size (Cohen's d)\n",
    "        d = (df[df[target_col]==1][col].mean() - df[df[target_col]==0][col].mean()) / \\\n",
    "            np.sqrt((df[df[target_col]==1][col].std()**2 + df[df[target_col]==0][col].std()**2) / 2)\n",
    "        \n",
    "        stats_results[col] = {\n",
    "            'p_value': p_value,\n",
    "            'effect_size': d,\n",
    "            'mean_diff': df[df[target_col]==1][col].mean() - df[df[target_col]==0][col].mean()\n",
    "        }\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Correlation Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    correlations = df[numeric_cols + [target_col]].corr()[target_col].sort_values()\n",
    "    sns.barplot(x=correlations.values[:-1], y=correlations.index[:-1])\n",
    "    plt.title(f'Correlation with {target_col}')\n",
    "    plt.xlabel('Correlation Coefficient')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Print Statistical Results\n",
    "    results_df = pd.DataFrame(stats_results).T\n",
    "    results_df = results_df.sort_values('p_value')\n",
    "    print(\"\\nStatistical Analysis Results:\")\n",
    "    print(\"\\nTop 10 Most Significant Features:\")\n",
    "    print(results_df.head(10).round(4))\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Assuming your dataframe is called 'new_anomolly_data'\n",
    "# Run the analysis\n",
    "results = bivariate_analysis(new_anomaly_data, target_col='Y')\n",
    "\n",
    "# Additional Analysis: Distribution Plots for Top Features\n",
    "top_features = results.head(5).index.tolist()\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for idx, feature in enumerate(top_features, 1):\n",
    "    plt.subplot(2, 3, idx)\n",
    "    sns.kdeplot(data=new_anomaly_data, x=feature, hue='Y', common_norm=False)\n",
    "    plt.title(f'Distribution of {feature} by Y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create summary table of the most important relationships\n",
    "summary_table = pd.DataFrame({\n",
    "    'Feature': top_features,\n",
    "    'P-Value': results.loc[top_features, 'p_value'],\n",
    "    'Effect Size': results.loc[top_features, 'effect_size'],\n",
    "    'Mean Difference': results.loc[top_features, 'mean_diff']\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\nTop Features Summary:\")\n",
    "print(summary_table)\n",
    "\n",
    "# Optional: Chi-square test for categorical variables\n",
    "def analyze_categorical_relationships(df, target_col='Y'):\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    if categorical_cols:\n",
    "        print(\"\\nChi-square tests for categorical variables:\")\n",
    "        for col in categorical_cols:\n",
    "            chi2, p_val, dof, expected = stats.chi2_contingency(\n",
    "                pd.crosstab(df[col], df[target_col])\n",
    "            )\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"Chi-square statistic: {chi2:.4f}\")\n",
    "            print(f\"p-value: {p_val:.4f}\")\n",
    "\n",
    "# Call the function\n",
    "analyze_categorical_relationships(data_with_features, target_col='Y')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomolly-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
